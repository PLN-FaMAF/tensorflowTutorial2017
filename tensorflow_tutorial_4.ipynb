{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inspecting the model\n",
    "\n",
    "In this notebook we will present some techniques to log and visualize the model behaviour during training. Neural networks have been widely critized because of the lack of interpretation of their internal parameters.\n",
    "\n",
    "The lack of interpretability leads, among other thigns, to make neural models error prone. While this is true, we still have some tools to try to debug our network and to understand what the model is doing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO read arrays\n",
    "input_data = input_data = np.random.random([200, 5])\n",
    "input_labels = np.random.randint(1, 20, 200)\n",
    "num_classes = 20  # TODO calculate this\n",
    "batch_size = 20\n",
    "\n",
    "train_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={\"input_data\": input_data},  # A dictionary mapping string to input tensors\n",
    "    y=input_labels,\n",
    "    batch_size=batch_size,\n",
    "    num_epochs=None,\n",
    "    shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The easiest way of logging values\n",
    "\n",
    "If you only need to see some numerical values during training, you can print them in the console (or notebook in this case).\n",
    "\n",
    "To add any operation that is performed inside the training cycle, the `Estimator.train` method provides hooks. Hooks, which are formally instances of subclasses of `SessionRunHook`, will be called after each epoch **TODO check this** to perform the operation you want, depending on the type of hook. In this particulaer case, the `LoggingTensorHook` will print in console the tensors we give as parameters, and we can personalize after how many iterations the print will occur. This will also work for the evaluate and predict methods.\n",
    "\n",
    "To try the logging, just run the above training phase with the model we presented on the previous notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set up logging for predictions\n",
    "# Log the values in the \"Softmax\" tensor with label \"probabilities\"\n",
    "tensors_to_log = {\"probabilities\": \"softmax_tensor\"}\n",
    "logging_hook = tf.train.LoggingTensorHook(\n",
    "    tensors=tensors_to_log, every_n_iter=50)\n",
    "\n",
    "# Train the model\n",
    "mlp_classifier.train(\n",
    "    input_fn=train_input_fn,\n",
    "    steps=2000,\n",
    "    hooks=[logging_hook]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensorboard\n",
    "\n",
    "There is a limit to what we can print and interpret on console. Tensorflow comes with its own (and very complete) visualization tool: Tensorboard. In the rest of this tutorial, we will explain how to use Tensorboard to log scalar values like metrics of performance, histogram values like the activation of the cells in each network layer. In the next notebook we will see how to plot and inspect embeddings to show how the document embeddings relate to each other.\n",
    "\n",
    "Tensorboard is based on operations called summaries which record the tensor variable to log. Unlike the previous example, summaries, as all operations, must be compiled along with the model in order to be included in the execution graph. There is a summary operation for each type of data that we want to log: scalars, tensors (histogram or tensor), audio, images and text.\n",
    "\n",
    "In any tensorflow code where we want to save variables for Tensorboard, we have to add some code with the following structure:\n",
    "\n",
    "```\n",
    "    # The definition of your variables\n",
    "    ...\n",
    "    # The summary operations\n",
    "    tf.summary.histogram('softmax_tensor', probabilities_tensor)\n",
    "    tf.summary.scalar('loss', loss_value)\n",
    "    \n",
    "    # The merge operation\n",
    "    tf.summary.merge_all()\n",
    "    \n",
    "    # The write operation\n",
    "    ...\n",
    "```\n",
    "\n",
    "The `summary.histogram` and `summary.scalar` will evaluate the value of the variable at that point during the execution of the graph. Then, the `summary.merge_all` takes all the summary operations added up to that moment and creates a single output with all the information, so the result can be written to disk only once.\n",
    "\n",
    "Now, for older versions of tensorflow or if you are not using Estimators, the write operation uses the `summary.FileWriter` class to write your data. On the other hand, the Estimator wraps this task into a special Hook for summary operations called `SummarySaverHook`.\n",
    "\n",
    "In the following cell we have the same model structure as before (with less comments) and we add the summary operations to the graph, and finally the summary hook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_model(input_data, mode):\n",
    "    \"\"\"Creates the model layers.\n",
    "    \n",
    "    Args:\n",
    "        input_data: a Tensor with shape [batch_size, feature_size]\n",
    "    \n",
    "    Returns:\n",
    "        The logits of the output layer.\"\"\"\n",
    "    hidden1 = tf.layers.dense(inputs=input_data, units=250, activation=tf.nn.relu,\n",
    "                              name='hidden_layer_1')\n",
    "    hidden2 = tf.layers.dense(inputs=hidden1, units=100, activation=tf.nn.relu,\n",
    "                              name='hidden_layer_2')\n",
    "    dropout = tf.layers.dropout(inputs=hidden2, rate=0.4,\n",
    "                                training=(mode == tf.estimator.ModeKeys.TRAIN))\n",
    "    logits = tf.layers.dense(inputs=dropout, units=num_classes, name='logits')\n",
    "\n",
    "    return (logits)\n",
    "\n",
    "def mlp_model_fn(features, labels, mode):\n",
    "    \"\"\"Model function for MLP.\n",
    "    \n",
    "    Args:\n",
    "        features: a dictionary where the values are input tensors with shape\n",
    "            [batch_size, feature_size]\n",
    "        labels: a tensor with shape [batch_size]\n",
    "        mode: a constant, one of `tf.estimator.ModeKeys.`\n",
    "    \n",
    "    Returns:\n",
    "        An instance of ´tf.estimator.EstimatorSpec´.\n",
    "    \"\"\"\n",
    "    logits = build_model(features['input_data'], mode)\n",
    "\n",
    "    predictions = {\n",
    "        'classes': tf.argmax(input=logits, axis=1),\n",
    "        'probabilities': tf.nn.softmax(logits, name='softmax_tensor')\n",
    "    }\n",
    "    # Add the summary operation to log the tensor with the predictions\n",
    "    tf.summary.histogram('softmax_tensor', predictions['probabilities'])\n",
    "    \n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions)\n",
    "\n",
    "    onehot_labels = tf.one_hot(indices=tf.cast(labels, tf.int32), depth=num_classes)\n",
    "    loss = tf.losses.softmax_cross_entropy(\n",
    "      onehot_labels=onehot_labels, logits=logits)\n",
    "    \n",
    "    # Add the summary operation to log the value of the loss\n",
    "    tf.summary.scalar(\"loss\", loss)\n",
    "\n",
    "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "        # Add the summary hook with the merge operation as parameter\n",
    "        logging_hook = tf.train.SummarySaverHook(save_steps=50, output_dir='/tmp/20news_mlp_model',\n",
    "                                                 summary_op=tf.summary.merge_all())\n",
    "        optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.001)\n",
    "        train_op = optimizer.minimize(\n",
    "            loss=loss,\n",
    "            global_step=tf.train.get_global_step())\n",
    "        return tf.estimator.EstimatorSpec(mode=mode, loss=loss, train_op=train_op,\n",
    "                                          training_hooks=[logging_hook])\n",
    "\n",
    "    eval_metric_ops = {\n",
    "        'accuracy': tf.metrics.accuracy(labels=labels, predictions=predictions['classes'])\n",
    "    }\n",
    "    return tf.estimator.EstimatorSpec(\n",
    "        mode=mode, loss=loss, eval_metric_ops=eval_metric_ops)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can create the Estimator as before with the summary operations compiled into the graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_save_summary_steps': 100, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_session_config': None, '_model_dir': '20news_mlp_model', '_tf_random_seed': 1, '_save_checkpoints_secs': 600, '_save_checkpoints_steps': None}\n"
     ]
    }
   ],
   "source": [
    "mlp_classifier = tf.estimator.Estimator(\n",
    "    model_fn=mlp_model_fn, model_dir=\"20news_mlp_model_summaries\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from 20news_mlp_model/model.ckpt-4000\n"
     ]
    },
    {
     "ename": "NotFoundError",
     "evalue": "Key logits/kernel not found in checkpoint\n\t [[Node: save/RestoreV2_6 = RestoreV2[dtypes=[DT_DOUBLE], _device=\"/job:localhost/replica:0/task:0/cpu:0\"](_arg_save/Const_0_0, save/RestoreV2_6/tensor_names, save/RestoreV2_6/shape_and_slices)]]\n\nCaused by op 'save/RestoreV2_6', defined at:\n  File \"/home/mteruel/anaconda2/envs/keras/lib/python3.5/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/mteruel/anaconda2/envs/keras/lib/python3.5/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/mteruel/anaconda2/envs/keras/lib/python3.5/site-packages/ipykernel/__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"/home/mteruel/anaconda2/envs/keras/lib/python3.5/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/mteruel/anaconda2/envs/keras/lib/python3.5/site-packages/ipykernel/kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"/home/mteruel/anaconda2/envs/keras/lib/python3.5/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/home/mteruel/anaconda2/envs/keras/lib/python3.5/site-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/home/mteruel/anaconda2/envs/keras/lib/python3.5/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/mteruel/anaconda2/envs/keras/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/home/mteruel/anaconda2/envs/keras/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/mteruel/anaconda2/envs/keras/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/mteruel/anaconda2/envs/keras/lib/python3.5/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/mteruel/anaconda2/envs/keras/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/mteruel/anaconda2/envs/keras/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/mteruel/anaconda2/envs/keras/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/mteruel/anaconda2/envs/keras/lib/python3.5/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/mteruel/anaconda2/envs/keras/lib/python3.5/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/mteruel/anaconda2/envs/keras/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2698, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/mteruel/anaconda2/envs/keras/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2808, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/mteruel/anaconda2/envs/keras/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2862, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-9-c8193b1c4be0>\", line 1, in <module>\n    mlp_classifier.train(input_fn=train_input_fn, steps=2000)\n  File \"/home/mteruel/anaconda2/envs/keras/lib/python3.5/site-packages/tensorflow/python/estimator/estimator.py\", line 241, in train\n    loss = self._train_model(input_fn=input_fn, hooks=hooks)\n  File \"/home/mteruel/anaconda2/envs/keras/lib/python3.5/site-packages/tensorflow/python/estimator/estimator.py\", line 609, in _train_model\n    config=self._session_config) as mon_sess:\n  File \"/home/mteruel/anaconda2/envs/keras/lib/python3.5/site-packages/tensorflow/python/training/monitored_session.py\", line 352, in MonitoredTrainingSession\n    stop_grace_period_secs=stop_grace_period_secs)\n  File \"/home/mteruel/anaconda2/envs/keras/lib/python3.5/site-packages/tensorflow/python/training/monitored_session.py\", line 648, in __init__\n    stop_grace_period_secs=stop_grace_period_secs)\n  File \"/home/mteruel/anaconda2/envs/keras/lib/python3.5/site-packages/tensorflow/python/training/monitored_session.py\", line 477, in __init__\n    self._sess = _RecoverableSession(self._coordinated_creator)\n  File \"/home/mteruel/anaconda2/envs/keras/lib/python3.5/site-packages/tensorflow/python/training/monitored_session.py\", line 822, in __init__\n    _WrappedSession.__init__(self, self._create_session())\n  File \"/home/mteruel/anaconda2/envs/keras/lib/python3.5/site-packages/tensorflow/python/training/monitored_session.py\", line 827, in _create_session\n    return self._sess_creator.create_session()\n  File \"/home/mteruel/anaconda2/envs/keras/lib/python3.5/site-packages/tensorflow/python/training/monitored_session.py\", line 538, in create_session\n    self.tf_sess = self._session_creator.create_session()\n  File \"/home/mteruel/anaconda2/envs/keras/lib/python3.5/site-packages/tensorflow/python/training/monitored_session.py\", line 403, in create_session\n    self._scaffold.finalize()\n  File \"/home/mteruel/anaconda2/envs/keras/lib/python3.5/site-packages/tensorflow/python/training/monitored_session.py\", line 205, in finalize\n    self._saver.build()\n  File \"/home/mteruel/anaconda2/envs/keras/lib/python3.5/site-packages/tensorflow/python/training/saver.py\", line 1170, in build\n    restore_sequentially=self._restore_sequentially)\n  File \"/home/mteruel/anaconda2/envs/keras/lib/python3.5/site-packages/tensorflow/python/training/saver.py\", line 687, in build\n    restore_sequentially, reshape)\n  File \"/home/mteruel/anaconda2/envs/keras/lib/python3.5/site-packages/tensorflow/python/training/saver.py\", line 450, in _AddShardedRestoreOps\n    name=\"restore_shard\"))\n  File \"/home/mteruel/anaconda2/envs/keras/lib/python3.5/site-packages/tensorflow/python/training/saver.py\", line 407, in _AddRestoreOps\n    tensors = self.restore_op(filename_tensor, saveable, preferred_shard)\n  File \"/home/mteruel/anaconda2/envs/keras/lib/python3.5/site-packages/tensorflow/python/training/saver.py\", line 247, in restore_op\n    [spec.tensor.dtype])[0])\n  File \"/home/mteruel/anaconda2/envs/keras/lib/python3.5/site-packages/tensorflow/python/ops/gen_io_ops.py\", line 640, in restore_v2\n    dtypes=dtypes, name=name)\n  File \"/home/mteruel/anaconda2/envs/keras/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py\", line 767, in apply_op\n    op_def=op_def)\n  File \"/home/mteruel/anaconda2/envs/keras/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 2506, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/home/mteruel/anaconda2/envs/keras/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 1269, in __init__\n    self._traceback = _extract_stack()\n\nNotFoundError (see above for traceback): Key logits/kernel not found in checkpoint\n\t [[Node: save/RestoreV2_6 = RestoreV2[dtypes=[DT_DOUBLE], _device=\"/job:localhost/replica:0/task:0/cpu:0\"](_arg_save/Const_0_0, save/RestoreV2_6/tensor_names, save/RestoreV2_6/shape_and_slices)]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda2/envs/keras/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1138\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1139\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1140\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/keras/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1120\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1121\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/keras/lib/python3.5/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m                 \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/keras/lib/python3.5/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36mraise_exception_on_not_ok_status\u001b[0;34m()\u001b[0m\n\u001b[1;32m    465\u001b[0m           \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpywrap_tensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 466\u001b[0;31m           pywrap_tensorflow.TF_GetCode(status))\n\u001b[0m\u001b[1;32m    467\u001b[0m   \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotFoundError\u001b[0m: Key logits/kernel not found in checkpoint\n\t [[Node: save/RestoreV2_6 = RestoreV2[dtypes=[DT_DOUBLE], _device=\"/job:localhost/replica:0/task:0/cpu:0\"](_arg_save/Const_0_0, save/RestoreV2_6/tensor_names, save/RestoreV2_6/shape_and_slices)]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-c8193b1c4be0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmlp_classifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_input_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda2/envs/keras/lib/python3.5/site-packages/tensorflow/python/estimator/estimator.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, input_fn, hooks, steps, max_steps)\u001b[0m\n\u001b[1;32m    239\u001b[0m       \u001b[0mhooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStopAtStepHook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 241\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhooks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    242\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Loss for final step: %s.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/keras/lib/python3.5/site-packages/tensorflow/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_train_model\u001b[0;34m(self, input_fn, hooks)\u001b[0m\n\u001b[1;32m    607\u001b[0m           \u001b[0msave_checkpoint_secs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Saving is handled by a hook.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    608\u001b[0m           \u001b[0msave_summaries_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_summary_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 609\u001b[0;31m           config=self._session_config) as mon_sess:\n\u001b[0m\u001b[1;32m    610\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    611\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmon_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/keras/lib/python3.5/site-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mMonitoredTrainingSession\u001b[0;34m(master, is_chief, checkpoint_dir, scaffold, hooks, chief_only_hooks, save_checkpoint_secs, save_summaries_steps, save_summaries_secs, config, stop_grace_period_secs, log_step_count_steps)\u001b[0m\n\u001b[1;32m    350\u001b[0m     \u001b[0mall_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhooks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m   return MonitoredSession(session_creator=session_creator, hooks=all_hooks,\n\u001b[0;32m--> 352\u001b[0;31m                           stop_grace_period_secs=stop_grace_period_secs)\n\u001b[0m\u001b[1;32m    353\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/keras/lib/python3.5/site-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, session_creator, hooks, stop_grace_period_secs)\u001b[0m\n\u001b[1;32m    646\u001b[0m     super(MonitoredSession, self).__init__(\n\u001b[1;32m    647\u001b[0m         \u001b[0msession_creator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshould_recover\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 648\u001b[0;31m         stop_grace_period_secs=stop_grace_period_secs)\n\u001b[0m\u001b[1;32m    649\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    650\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/keras/lib/python3.5/site-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, session_creator, hooks, should_recover, stop_grace_period_secs)\u001b[0m\n\u001b[1;32m    475\u001b[0m         stop_grace_period_secs=stop_grace_period_secs)\n\u001b[1;32m    476\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mshould_recover\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_RecoverableSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_coordinated_creator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_coordinated_creator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/keras/lib/python3.5/site-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, sess_creator)\u001b[0m\n\u001b[1;32m    820\u001b[0m     \"\"\"\n\u001b[1;32m    821\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess_creator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess_creator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 822\u001b[0;31m     \u001b[0m_WrappedSession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    823\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_create_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/keras/lib/python3.5/site-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36m_create_session\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    825\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    826\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 827\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess_creator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    828\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0m_PREEMPTION_ERRORS\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    829\u001b[0m         logging.info('An error was raised while a session was being created. '\n",
      "\u001b[0;32m~/anaconda2/envs/keras/lib/python3.5/site-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mcreate_session\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    536\u001b[0m       \u001b[0;34m\"\"\"Creates a coordinated session.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    537\u001b[0m       \u001b[0;31m# Keep the tf_sess for unit testing.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 538\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtf_sess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session_creator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    539\u001b[0m       \u001b[0;31m# We don't want coordinator to suppress any exception.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoord\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcoordinator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCoordinator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclean_stop_exception_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/keras/lib/python3.5/site-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mcreate_session\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    410\u001b[0m         \u001b[0minit_op\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_scaffold\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_op\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    411\u001b[0m         \u001b[0minit_feed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_scaffold\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_feed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 412\u001b[0;31m         init_fn=self._scaffold.init_fn)\n\u001b[0m\u001b[1;32m    413\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/keras/lib/python3.5/site-packages/tensorflow/python/training/session_manager.py\u001b[0m in \u001b[0;36mprepare_session\u001b[0;34m(self, master, init_op, saver, checkpoint_dir, checkpoint_filename_with_path, wait_for_checkpoint, max_wait_secs, config, init_feed_dict, init_fn)\u001b[0m\n\u001b[1;32m    271\u001b[0m         \u001b[0mwait_for_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwait_for_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m         \u001b[0mmax_wait_secs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_wait_secs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 273\u001b[0;31m         config=config)\n\u001b[0m\u001b[1;32m    274\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_loaded_from_checkpoint\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0minit_op\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0minit_fn\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_local_init_op\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/keras/lib/python3.5/site-packages/tensorflow/python/training/session_manager.py\u001b[0m in \u001b[0;36m_restore_checkpoint\u001b[0;34m(self, master, saver, checkpoint_dir, checkpoint_filename_with_path, wait_for_checkpoint, max_wait_secs, config)\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[0;31m# Loads the checkpoint.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 205\u001b[0;31m     \u001b[0msaver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mckpt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_checkpoint_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    206\u001b[0m     \u001b[0msaver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecover_last_checkpoints\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mckpt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall_model_checkpoint_paths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/keras/lib/python3.5/site-packages/tensorflow/python/training/saver.py\u001b[0m in \u001b[0;36mrestore\u001b[0;34m(self, sess, save_path)\u001b[0m\n\u001b[1;32m   1546\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Restoring parameters from %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1547\u001b[0m     sess.run(self.saver_def.restore_op_name,\n\u001b[0;32m-> 1548\u001b[0;31m              {self.saver_def.filename_tensor_name: save_path})\n\u001b[0m\u001b[1;32m   1549\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1550\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/keras/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    787\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 789\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    790\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/keras/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    995\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    996\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 997\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    998\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    999\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/keras/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1130\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1131\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1132\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1133\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m~/anaconda2/envs/keras/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1150\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1152\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotFoundError\u001b[0m: Key logits/kernel not found in checkpoint\n\t [[Node: save/RestoreV2_6 = RestoreV2[dtypes=[DT_DOUBLE], _device=\"/job:localhost/replica:0/task:0/cpu:0\"](_arg_save/Const_0_0, save/RestoreV2_6/tensor_names, save/RestoreV2_6/shape_and_slices)]]\n\nCaused by op 'save/RestoreV2_6', defined at:\n  File \"/home/mteruel/anaconda2/envs/keras/lib/python3.5/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/mteruel/anaconda2/envs/keras/lib/python3.5/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/mteruel/anaconda2/envs/keras/lib/python3.5/site-packages/ipykernel/__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"/home/mteruel/anaconda2/envs/keras/lib/python3.5/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/mteruel/anaconda2/envs/keras/lib/python3.5/site-packages/ipykernel/kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"/home/mteruel/anaconda2/envs/keras/lib/python3.5/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/home/mteruel/anaconda2/envs/keras/lib/python3.5/site-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/home/mteruel/anaconda2/envs/keras/lib/python3.5/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/mteruel/anaconda2/envs/keras/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/home/mteruel/anaconda2/envs/keras/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/mteruel/anaconda2/envs/keras/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/mteruel/anaconda2/envs/keras/lib/python3.5/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/mteruel/anaconda2/envs/keras/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/mteruel/anaconda2/envs/keras/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/mteruel/anaconda2/envs/keras/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/mteruel/anaconda2/envs/keras/lib/python3.5/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/mteruel/anaconda2/envs/keras/lib/python3.5/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/mteruel/anaconda2/envs/keras/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2698, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/mteruel/anaconda2/envs/keras/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2808, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/mteruel/anaconda2/envs/keras/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2862, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-9-c8193b1c4be0>\", line 1, in <module>\n    mlp_classifier.train(input_fn=train_input_fn, steps=2000)\n  File \"/home/mteruel/anaconda2/envs/keras/lib/python3.5/site-packages/tensorflow/python/estimator/estimator.py\", line 241, in train\n    loss = self._train_model(input_fn=input_fn, hooks=hooks)\n  File \"/home/mteruel/anaconda2/envs/keras/lib/python3.5/site-packages/tensorflow/python/estimator/estimator.py\", line 609, in _train_model\n    config=self._session_config) as mon_sess:\n  File \"/home/mteruel/anaconda2/envs/keras/lib/python3.5/site-packages/tensorflow/python/training/monitored_session.py\", line 352, in MonitoredTrainingSession\n    stop_grace_period_secs=stop_grace_period_secs)\n  File \"/home/mteruel/anaconda2/envs/keras/lib/python3.5/site-packages/tensorflow/python/training/monitored_session.py\", line 648, in __init__\n    stop_grace_period_secs=stop_grace_period_secs)\n  File \"/home/mteruel/anaconda2/envs/keras/lib/python3.5/site-packages/tensorflow/python/training/monitored_session.py\", line 477, in __init__\n    self._sess = _RecoverableSession(self._coordinated_creator)\n  File \"/home/mteruel/anaconda2/envs/keras/lib/python3.5/site-packages/tensorflow/python/training/monitored_session.py\", line 822, in __init__\n    _WrappedSession.__init__(self, self._create_session())\n  File \"/home/mteruel/anaconda2/envs/keras/lib/python3.5/site-packages/tensorflow/python/training/monitored_session.py\", line 827, in _create_session\n    return self._sess_creator.create_session()\n  File \"/home/mteruel/anaconda2/envs/keras/lib/python3.5/site-packages/tensorflow/python/training/monitored_session.py\", line 538, in create_session\n    self.tf_sess = self._session_creator.create_session()\n  File \"/home/mteruel/anaconda2/envs/keras/lib/python3.5/site-packages/tensorflow/python/training/monitored_session.py\", line 403, in create_session\n    self._scaffold.finalize()\n  File \"/home/mteruel/anaconda2/envs/keras/lib/python3.5/site-packages/tensorflow/python/training/monitored_session.py\", line 205, in finalize\n    self._saver.build()\n  File \"/home/mteruel/anaconda2/envs/keras/lib/python3.5/site-packages/tensorflow/python/training/saver.py\", line 1170, in build\n    restore_sequentially=self._restore_sequentially)\n  File \"/home/mteruel/anaconda2/envs/keras/lib/python3.5/site-packages/tensorflow/python/training/saver.py\", line 687, in build\n    restore_sequentially, reshape)\n  File \"/home/mteruel/anaconda2/envs/keras/lib/python3.5/site-packages/tensorflow/python/training/saver.py\", line 450, in _AddShardedRestoreOps\n    name=\"restore_shard\"))\n  File \"/home/mteruel/anaconda2/envs/keras/lib/python3.5/site-packages/tensorflow/python/training/saver.py\", line 407, in _AddRestoreOps\n    tensors = self.restore_op(filename_tensor, saveable, preferred_shard)\n  File \"/home/mteruel/anaconda2/envs/keras/lib/python3.5/site-packages/tensorflow/python/training/saver.py\", line 247, in restore_op\n    [spec.tensor.dtype])[0])\n  File \"/home/mteruel/anaconda2/envs/keras/lib/python3.5/site-packages/tensorflow/python/ops/gen_io_ops.py\", line 640, in restore_v2\n    dtypes=dtypes, name=name)\n  File \"/home/mteruel/anaconda2/envs/keras/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py\", line 767, in apply_op\n    op_def=op_def)\n  File \"/home/mteruel/anaconda2/envs/keras/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 2506, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/home/mteruel/anaconda2/envs/keras/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 1269, in __init__\n    self._traceback = _extract_stack()\n\nNotFoundError (see above for traceback): Key logits/kernel not found in checkpoint\n\t [[Node: save/RestoreV2_6 = RestoreV2[dtypes=[DT_DOUBLE], _device=\"/job:localhost/replica:0/task:0/cpu:0\"](_arg_save/Const_0_0, save/RestoreV2_6/tensor_names, save/RestoreV2_6/shape_and_slices)]]\n"
     ]
    }
   ],
   "source": [
    "mlp_classifier.train(input_fn=train_input_fn, steps=2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The next thing to do is to go to the Tensorboard dashboard and inspect the obtained values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:keras]",
   "language": "python",
   "name": "conda-env-keras-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
