{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train and visualize a model in Tensorflow - Part 4: Inspecting the model\n",
    "\n",
    "Neural networks have been widely critized because of the lack of interpretation of their internal parameters. In this notebook we will present some techniques to log and visualize the model behaviour during training.\n",
    "\n",
    "The lack of interpretability leads, among other thigns, to make neural models error prone. While this is true, we still have some tools to try to debug our network and to understand what the model is doing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset into a numpy keyed structure\n",
    "newsgroups = np.load('./resources/newsgroup.npz')\n",
    "\n",
    "# Define the batch size and the number of labels\n",
    "batch_size = 100\n",
    "num_classes = newsgroups['labels'].shape[0]\n",
    "\n",
    "def dataset_input_fn(dataset):\n",
    "    \"\"\"\n",
    "    Creates an input function using the `numpy_input_fn` method from\n",
    "    tensorflow, based on the dataset we want to use.\n",
    "    \n",
    "    Args:\n",
    "        dataset: String that represents the dataset (should be `train` or `test`)\n",
    "    \n",
    "    Returns:\n",
    "        An `numpy_input_fn` function to feed to an estimator\n",
    "    \"\"\"\n",
    "    assert dataset in ('train', 'test'), \"The selected dataset should be `train` or `test`\"\n",
    "    \n",
    "    return tf.estimator.inputs.numpy_input_fn(\n",
    "        x={'input_data': newsgroups['%s_data' % dataset]},\n",
    "        y=newsgroups['%s_target' % dataset],\n",
    "        batch_size=batch_size,\n",
    "        num_epochs=1 if dataset == 'test' else None,\n",
    "        shuffle=dataset == 'train'\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The easiest way of logging values\n",
    "\n",
    "If you only need to see some numerical values during training, you can print them in the console (or notebook in this case).\n",
    "\n",
    "To add any operation that is performed inside the training cycle, the `Estimator.train` method provides hooks. Hooks, which are formally instances of subclasses of `SessionRunHook`, will be called after each epoch iteration to perform the operation you want, depending on the type of hook. In this particulaer case, the `LoggingTensorHook` will print in console the tensors we give as parameters, and we can personalize after how many iterations the print will occur. This will also work for the evaluate and predict methods.\n",
    "\n",
    "To try the logging, just run the above training phase with the model we presented on the previous notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set up logging for predictions\n",
    "# Log the values in the \"Softmax\" tensor with label \"probabilities\"\n",
    "tensors_to_log = {'probabilities': 'softmax_tensor'}\n",
    "logging_hook = tf.train.LoggingTensorHook(\n",
    "    tensors=tensors_to_log, every_n_iter=50)\n",
    "\n",
    "# Train the model\n",
    "mlp_classifier.train(\n",
    "    input_fn=dataset_input_fn('train'),\n",
    "    steps=2000,\n",
    "    hooks=[logging_hook]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensorboard\n",
    "\n",
    "There is a limit to what we can print and interpret on console. Tensorflow comes with its own (and very complete) visualization tool: Tensorboard. In the rest of this tutorial, we will explain how to use Tensorboard to log scalar values like metrics of performance, histogram values like the activation of the cells in each network layer. In the next notebook we will see how to plot and inspect embeddings to show how the document embeddings relate to each other.\n",
    "\n",
    "Tensorboard is based on operations called summaries which record the tensor variable to log. Unlike the previous example, summaries, as all operations, must be compiled along with the model in order to be included in the execution graph. There is a summary operation for each type of data that we want to log: scalars, tensors (histogram or tensor), audio, images and text.\n",
    "\n",
    "In any tensorflow code where we want to save variables for Tensorboard, we have to add some code with the following structure:\n",
    "\n",
    "```\n",
    "    # The definition of your variables\n",
    "    ...\n",
    "    # The summary operations\n",
    "    tf.summary.histogram('softmax_tensor', probabilities_tensor)\n",
    "    tf.summary.scalar('loss', loss_value)\n",
    "    \n",
    "    # The merge operation\n",
    "    tf.summary.merge_all()\n",
    "    \n",
    "    # The write operation\n",
    "    ...\n",
    "```\n",
    "\n",
    "The `summary.histogram` and `summary.scalar` will evaluate the value of the variable at that point during the execution of the graph. Then, the `summary.merge_all` takes all the summary operations added up to that moment and creates a single output with all the information, so the result can be written to disk only once.\n",
    "\n",
    "Now, for older versions of tensorflow or if you are not using Estimators, the write operation uses the `summary.FileWriter` class to write your data. On the other hand, the Estimator wraps this task into a special Hook for summary operations called `SummarySaverHook`.\n",
    "\n",
    "In the following cell we have the same model structure as before (with less comments) and we add the summary operations to the graph, and finally the summary hook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_model(input_data, mode):\n",
    "    \"\"\"Creates the model layers.\n",
    "    \n",
    "    Args:\n",
    "        input_data: a Tensor with shape [batch_size, feature_size]\n",
    "    \n",
    "    Returns:\n",
    "        The logits of the output layer.\"\"\"\n",
    "    hidden1 = tf.layers.dense(inputs=input_data, units=250, activation=tf.nn.relu,\n",
    "                              name='hidden_layer_1')\n",
    "    hidden2 = tf.layers.dense(inputs=hidden1, units=100, activation=tf.nn.relu,\n",
    "                              name='hidden_layer_2')\n",
    "    dropout = tf.layers.dropout(inputs=hidden2, rate=0.4,\n",
    "                                training=(mode == tf.estimator.ModeKeys.TRAIN))\n",
    "    logits = tf.layers.dense(inputs=dropout, units=num_classes, name='logits')\n",
    "\n",
    "    return (logits)\n",
    "\n",
    "def mlp_model_fn(features, labels, mode):\n",
    "    \"\"\"Model function for MLP.\n",
    "    \n",
    "    Args:\n",
    "        features: a dictionary where the values are input tensors with shape\n",
    "            [batch_size, feature_size]\n",
    "        labels: a tensor with shape [batch_size]\n",
    "        mode: a constant, one of `tf.estimator.ModeKeys.`\n",
    "    \n",
    "    Returns:\n",
    "        An instance of ´tf.estimator.EstimatorSpec´.\n",
    "    \"\"\"\n",
    "    logits = build_model(features['input_data'], mode)\n",
    "\n",
    "    predictions = {\n",
    "        'classes': tf.argmax(input=logits, axis=1),\n",
    "        'probabilities': tf.nn.softmax(logits, name='softmax_tensor')\n",
    "    }\n",
    "    \n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions)\n",
    "\n",
    "    # Add the summary operation to log the tensor with the predictions\n",
    "    tf.summary.histogram('softmax_tensor', predictions['probabilities'])\n",
    "\n",
    "    onehot_labels = tf.one_hot(indices=tf.cast(labels, tf.int32), depth=num_classes)\n",
    "    loss = tf.losses.softmax_cross_entropy(\n",
    "      onehot_labels=onehot_labels, logits=logits)\n",
    "\n",
    "    accuracy_op = tf.metrics.accuracy(labels=labels, predictions=predictions['classes'], name='accuracy')\n",
    "    # Add the summary operation to log the value of the accuracy\n",
    "    tf.summary.scalar('accuracy', accuracy_op[1])\n",
    "    summary_op = tf.summary.merge_all()\n",
    "    summary_hook = tf.train.SummarySaverHook(save_steps=100, summary_op=summary_op)\n",
    "\n",
    "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "        \n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate=0.01)\n",
    "        train_op = optimizer.minimize(loss=loss,\n",
    "                                      global_step=tf.train.get_global_step())\n",
    "        return tf.estimator.EstimatorSpec(mode=mode, loss=loss, train_op=train_op,\n",
    "                                          training_hooks=[summary_hook])\n",
    "\n",
    "    eval_metric_ops = {'accuracy': accuracy_op}\n",
    "    return tf.estimator.EstimatorSpec(mode=mode, loss=loss, eval_metric_ops=eval_metric_ops,\n",
    "                                      evaluation_hooks=[summary_hook])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can create the Estimator as before with the summary operations compiled into the graph. Note that, as we have a different graph, we have to use a new model_dir or it would fail when loading the previous checkpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_classifier = tf.estimator.Estimator(\n",
    "    model_fn=mlp_model_fn, model_dir='20news_mlp_summaries')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mlp_classifier.train(input_fn=dataset_input_fn('train'), steps=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_classifier.evaluate(input_fn=dataset_input_fn('test'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The next thing to do is to go to the Tensorboard dashboard in the model directory and inspect the obtained values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiple iterations\n",
    "\n",
    "If we run the same experiment as before several times, the model will be restored from the last checkpoint and the training will recommence using the current weights and biases. Even more, if you don't use Estimators the results of different runs are stored in the same folder and coexists in a mess of metric values.\n",
    "\n",
    "We actually want to compare several runs of the same experiment, or perhaps compare the performance of several classifiers in the same graph. For that, we will change the structure of the directories and Tensorboard will organize and show the results accordingly. We will use an experiment counter to keep track of how many iterations we have done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "EXPERIMENT_COUNTER = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "mlp_classifier = tf.estimator.Estimator(\n",
    "    model_fn=mlp_model_fn,\n",
    "    model_dir=os.path.join('20news_mlp_summaries', 'iter{}'.format(EXPERIMENT_COUNTER)))\n",
    "mlp_classifier.train(input_fn=dataset_input_fn('train'), steps=2000)\n",
    "EXPERIMENT_COUNTER += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contrib: Monitoring performance while training\n",
    "\n",
    "We know so far how to visualize the metrics related to training, but it is more interesting to compare the performance of the classifier in the validation dataset. Furthermore, we would like to stop the training if the validation performance drops too much.\n",
    "\n",
    "In the contrib.learn module of tensorflow we found an `Experiment` class that will run the train and evaluation cycle for us. Even if this not hard to implement using a for loop, we recommend to use the functions provided by tensorflow as they support training on multiple servers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_classifier = tf.estimator.Estimator(\n",
    "    model_fn=mlp_model_fn,\n",
    "    model_dir=os.path.join('20news_mlp_model_summaries', 'iter{}'.format(EXPERIMENT_COUNTER)))\n",
    "\n",
    "experiment = tf.contrib.learn.Experiment(\n",
    "    mlp_classifier,\n",
    "    train_input_fn=train_input_fn,\n",
    "    eval_input_fn=eval_input_fn,\n",
    "    train_steps=1000,\n",
    "    train_steps_per_iteration=100\n",
    "    )\n",
    "experiment.continuous_train_and_eval()\n",
    "\n",
    "EXPERIMENT_COUNTER += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Activity\n",
    "\n",
    " 1. Use Tensoboard to visualize, the precision and recall of several runs and several models in the same graph.\n",
    " 2. Create an early stop training cycle using the `contrib.learn.Experiment` class or the `tf.estimator.train_and_evaluate` function. This cycle must train the model until the performance on the test dataset drops."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:keras]",
   "language": "python",
   "name": "conda-env-keras-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
