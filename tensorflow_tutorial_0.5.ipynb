{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train and visualize a model in Tensorflow - Part 0.5 (optional): Dataset Preprocessing\n",
    "\n",
    "This notebook is optional for those who want to follow how we got the dataset we are using for the tutorial. For this tutorial you need to previously do all the configuration steps explained in **tutorial 0**, plus install the optional libraries (particularly `scikit-learn` and `gensim`).\n",
    "\n",
    "## Dataset Download\n",
    "\n",
    "The task we choose to work in this tutorial is document classification using the 20 Newsgroup Corpus, which is a standard resource for such task. It is a corpus of emails with a topic. For information on the 20 Newsgroup Corpus please refer to the [official website of the project](http://qwone.com/~jason/20Newsgroups/). \n",
    "\n",
    "For this tutorial we will be using the dataset with duplicates removed and only \"From\" and \"Subject\" headers. It is the file named [20news-18828.tar.gz](http://qwone.com/~jason/20Newsgroups/20news-18828.tar.gz).\n",
    "\n",
    "For the word embeddings we will be using Word2Vec's pre-trained embeddings on the [Google News corpus](https://cs.famaf.unc.edu.ar/~ccardellino/resources/word_vectors/google/GoogleNews-vectors-negative300.bin.gz).\n",
    "\n",
    "### Extracting the data\n",
    "\n",
    "For the preprocessing we need to load the 20 Newsgroup data and the Word2Vec's model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, print_function, unicode_literals\n",
    "\n",
    "import fnmatch\n",
    "import gensim\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = gensim.models.KeyedVectors.load_word2vec_format('./resources/GoogleNews-vectors-negative300.bin.gz',\n",
    "                                                        binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_files(path, file_pattern='*'):\n",
    "    for root, _, filenames in os.walk(path):\n",
    "        for filename in fnmatch.filter(filenames, file_pattern):\n",
    "            yield os.path.join(root, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "files_20ng = sorted(find_files('./resources/20newsgroup/'))\n",
    "labels = [os.path.basename(os.path.dirname(fname)) for fname in sorted(files_20ng)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(input='filename', decode_error='replace', stop_words='english', max_features=10000)\n",
    "document_matrix = vectorizer.fit_transform(files_20ng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embedding_matrix = np.zeros((document_matrix.shape[1], model.vector_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for word, idx in vectorizer.vocabulary_.items():\n",
    "    if word in model:\n",
    "        embedding_matrix[idx, :] = model[word]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "document_matrix.dot(embedding_matrix).shape"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:pydata]",
   "language": "python",
   "name": "conda-env-pydata-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
